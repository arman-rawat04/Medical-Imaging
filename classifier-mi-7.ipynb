{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11739400,"sourceType":"datasetVersion","datasetId":7369674}],"dockerImageVersionId":31011,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport tensorflow as tf\n\ndevice=torch.device(\"cuda\" if torch.cuda.is_available() else 'cpu')\nprint(device)\n# Optional: Force GPU/CPU usage\nif tf.config.list_physical_devices('GPU'):\n    device = '/GPU:0'\n    print(\"Using GPU\")\nelse:\n    device = '/CPU:0'\n    print(\"Using CPU\")\n\nimport numpy as np\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.regularizers import l2\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\nfrom collections import Counter\n\n# Load data\nX_train = np.load('/kaggle/input/classifier-data/X_train.npy')\ny_train_raw = np.load('/kaggle/input/classifier-data/y_train.npy')\nX_test = np.load('/kaggle/input/classifier-data/X_test.npy')\ny_test_raw = np.load('/kaggle/input/classifier-data/y_test.npy')\n\n# Convert to binary labels\ny_train = (y_train_raw.sum(axis=1) > 0).astype(int)\ny_test = (y_test_raw.sum(axis=1) > 0).astype(int)\n\n# Scale features\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n# Class weights to handle imbalance\ncounter = Counter(y_train)\nweight_for_0 = (1 / counter[0]) * (len(y_train) / 2.0)\nweight_for_1 = (1 / counter[1]) * (len(y_train) / 2.0)\nclass_weight = {0: weight_for_0, 1: weight_for_1}\n\n# Model definition\nmodel = Sequential([\n    Dense(64, activation='relu', kernel_regularizer=l2(0.001), input_shape=(X_train_scaled.shape[1],)),\n    Dropout(0.5),\n    Dense(32, activation='relu', kernel_regularizer=l2(0.001)),\n    Dropout(0.5),\n    Dense(1, activation='sigmoid')\n])\n\n# Compile model\nmodel.compile(optimizer=Adam(learning_rate=0.0001),\n              loss='binary_crossentropy',\n              metrics=['accuracy'])\n\n# Callbacks\nearly_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\nlr_schedule = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5)\n\n# Train model\nhistory = model.fit(\n    X_train_scaled, y_train,\n    validation_split=0.2,\n    epochs=60,\n    batch_size=16,\n    class_weight=class_weight,\n    #callbacks=[early_stop, lr_schedule],\n    verbose=1\n)\n\n# Predict & evaluate\ny_pred_probs = model.predict(X_test_scaled)\ny_pred = (y_pred_probs > 0.5).astype(int)\n\nprint(\"Accuracy:\", accuracy_score(y_test, y_pred))\nprint(\"F1 Score:\", f1_score(y_test, y_pred))\nprint(\"Classification Report:\\n\", classification_report(y_test, y_pred))\nprint(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-09T01:15:45.137675Z","iopub.execute_input":"2025-05-09T01:15:45.138663Z","iopub.status.idle":"2025-05-09T01:15:52.959500Z","shell.execute_reply.started":"2025-05-09T01:15:45.138635Z","shell.execute_reply":"2025-05-09T01:15:52.958668Z"}},"outputs":[{"name":"stdout","text":"cuda\nUsing GPU\nEpoch 1/60\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 263ms/step - accuracy: 0.4660 - loss: 1.4057 - val_accuracy: 0.4231 - val_loss: 1.0440\nEpoch 2/60\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5107 - loss: 1.0109 - val_accuracy: 0.4231 - val_loss: 1.0399\nEpoch 3/60\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5302 - loss: 1.3281 - val_accuracy: 0.4231 - val_loss: 1.0364\nEpoch 4/60\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5773 - loss: 1.0853 - val_accuracy: 0.4615 - val_loss: 1.0333\nEpoch 5/60\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4755 - loss: 1.2767 - val_accuracy: 0.4615 - val_loss: 1.0289\nEpoch 6/60\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4558 - loss: 1.1454 - val_accuracy: 0.4615 - val_loss: 1.0252\nEpoch 7/60\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3978 - loss: 1.2217 - val_accuracy: 0.4615 - val_loss: 1.0181\nEpoch 8/60\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5525 - loss: 1.1365 - val_accuracy: 0.4615 - val_loss: 1.0126\nEpoch 9/60\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4851 - loss: 1.0362 - val_accuracy: 0.4615 - val_loss: 1.0089\nEpoch 10/60\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5310 - loss: 1.0277 - val_accuracy: 0.4615 - val_loss: 1.0058\nEpoch 11/60\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6546 - loss: 0.9114 - val_accuracy: 0.4615 - val_loss: 1.0007\nEpoch 12/60\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4768 - loss: 1.1365 - val_accuracy: 0.4615 - val_loss: 0.9942\nEpoch 13/60\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5370 - loss: 1.0726 - val_accuracy: 0.4615 - val_loss: 0.9874\nEpoch 14/60\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5057 - loss: 1.0528 - val_accuracy: 0.4615 - val_loss: 0.9837\nEpoch 15/60\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5468 - loss: 1.0338 - val_accuracy: 0.4615 - val_loss: 0.9804\nEpoch 16/60\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4579 - loss: 1.2201 - val_accuracy: 0.4615 - val_loss: 0.9786\nEpoch 17/60\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5932 - loss: 0.9727 - val_accuracy: 0.4615 - val_loss: 0.9746\nEpoch 18/60\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5767 - loss: 1.0393 - val_accuracy: 0.4615 - val_loss: 0.9696\nEpoch 19/60\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4836 - loss: 1.2740 - val_accuracy: 0.4615 - val_loss: 0.9640\nEpoch 20/60\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5936 - loss: 0.9420 - val_accuracy: 0.4615 - val_loss: 0.9616\nEpoch 21/60\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5711 - loss: 1.0609 - val_accuracy: 0.4615 - val_loss: 0.9606\nEpoch 22/60\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6352 - loss: 0.9648 - val_accuracy: 0.4615 - val_loss: 0.9580\nEpoch 23/60\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5584 - loss: 0.9212 - val_accuracy: 0.4615 - val_loss: 0.9538\nEpoch 24/60\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6058 - loss: 0.8422 - val_accuracy: 0.5000 - val_loss: 0.9496\nEpoch 25/60\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5793 - loss: 0.8602 - val_accuracy: 0.5000 - val_loss: 0.9442\nEpoch 26/60\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5397 - loss: 0.9709 - val_accuracy: 0.5000 - val_loss: 0.9402\nEpoch 27/60\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6900 - loss: 0.7593 - val_accuracy: 0.5000 - val_loss: 0.9376\nEpoch 28/60\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6186 - loss: 0.9628 - val_accuracy: 0.5000 - val_loss: 0.9358\nEpoch 29/60\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5753 - loss: 0.9337 - val_accuracy: 0.5000 - val_loss: 0.9342\nEpoch 30/60\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6184 - loss: 0.8720 - val_accuracy: 0.5000 - val_loss: 0.9339\nEpoch 31/60\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6821 - loss: 0.8895 - val_accuracy: 0.5000 - val_loss: 0.9338\nEpoch 32/60\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6324 - loss: 0.8271 - val_accuracy: 0.5000 - val_loss: 0.9348\nEpoch 33/60\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5763 - loss: 0.9530 - val_accuracy: 0.4615 - val_loss: 0.9344\nEpoch 34/60\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6629 - loss: 0.8264 - val_accuracy: 0.4615 - val_loss: 0.9322\nEpoch 35/60\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6267 - loss: 1.0330 - val_accuracy: 0.4615 - val_loss: 0.9293\nEpoch 36/60\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7549 - loss: 0.7973 - val_accuracy: 0.4615 - val_loss: 0.9252\nEpoch 37/60\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5808 - loss: 0.8728 - val_accuracy: 0.4615 - val_loss: 0.9257\nEpoch 38/60\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5843 - loss: 0.9205 - val_accuracy: 0.4615 - val_loss: 0.9239\nEpoch 39/60\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6741 - loss: 0.9094 - val_accuracy: 0.5000 - val_loss: 0.9230\nEpoch 40/60\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5158 - loss: 0.9608 - val_accuracy: 0.5000 - val_loss: 0.9243\nEpoch 41/60\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5812 - loss: 1.0063 - val_accuracy: 0.4615 - val_loss: 0.9226\nEpoch 42/60\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6067 - loss: 0.9240 - val_accuracy: 0.5000 - val_loss: 0.9198\nEpoch 43/60\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6721 - loss: 0.9396 - val_accuracy: 0.5000 - val_loss: 0.9181\nEpoch 44/60\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5968 - loss: 1.0067 - val_accuracy: 0.5000 - val_loss: 0.9170\nEpoch 45/60\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6652 - loss: 0.8555 - val_accuracy: 0.5000 - val_loss: 0.9146\nEpoch 46/60\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6944 - loss: 0.7785 - val_accuracy: 0.5000 - val_loss: 0.9120\nEpoch 47/60\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6263 - loss: 0.7738 - val_accuracy: 0.5000 - val_loss: 0.9089\nEpoch 48/60\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6020 - loss: 0.8375 - val_accuracy: 0.5000 - val_loss: 0.9060\nEpoch 49/60\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6419 - loss: 0.8333 - val_accuracy: 0.5000 - val_loss: 0.9046\nEpoch 50/60\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6653 - loss: 0.8649 - val_accuracy: 0.5000 - val_loss: 0.9020\nEpoch 51/60\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5723 - loss: 0.9423 - val_accuracy: 0.5000 - val_loss: 0.8990\nEpoch 52/60\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6347 - loss: 0.7996 - val_accuracy: 0.5000 - val_loss: 0.8965\nEpoch 53/60\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6621 - loss: 0.6730 - val_accuracy: 0.5000 - val_loss: 0.8961\nEpoch 54/60\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6286 - loss: 0.7911 - val_accuracy: 0.5000 - val_loss: 0.8931\nEpoch 55/60\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7082 - loss: 0.8544 - val_accuracy: 0.5000 - val_loss: 0.8897\nEpoch 56/60\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7098 - loss: 0.8234 - val_accuracy: 0.5000 - val_loss: 0.8901\nEpoch 57/60\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6333 - loss: 0.8040 - val_accuracy: 0.5000 - val_loss: 0.8905\nEpoch 58/60\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6500 - loss: 0.7943 - val_accuracy: 0.5000 - val_loss: 0.8908\nEpoch 59/60\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7337 - loss: 0.8265 - val_accuracy: 0.5000 - val_loss: 0.8893\nEpoch 60/60\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5472 - loss: 0.9323 - val_accuracy: 0.5385 - val_loss: 0.8894\n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step\nAccuracy: 0.6060606060606061\nF1 Score: 0.5517241379310345\nClassification Report:\n               precision    recall  f1-score   support\n\n           0       0.60      0.71      0.65        17\n           1       0.62      0.50      0.55        16\n\n    accuracy                           0.61        33\n   macro avg       0.61      0.60      0.60        33\nweighted avg       0.61      0.61      0.60        33\n\nConfusion Matrix:\n [[12  5]\n [ 8  8]]\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import (Conv2D, MaxPooling2D, Dropout, Flatten,\n                                     Dense, BatchNormalization)\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\nfrom sklearn.metrics import classification_report, confusion_matrix, f1_score\n\n# Load data\nX_train = np.load('/kaggle/input/classifier-data/X_train.npy')\nX_test = np.load('/kaggle/input/classifier-data/X_test.npy')\ny_train = np.load('/kaggle/input/classifier-data/y_train.npy')  # Assuming labels are in a separate file\ny_test = np.load('/kaggle/input/classifier-data/y_test.npy')  # Assuming labels are in a separate file\n\n# Preprocessing: Normalize the image data\nX_train = X_train.astype('float32') / 255.0\nX_test = X_test.astype('float32') / 255.0\n\n# Check the shape of the data\nprint(f\"Train shape: {X_train.shape}, Test shape: {X_test.shape}\")\n\n# Model architecture\nmodel = Sequential([\n    Conv2D(32, (3,3), activation='relu', input_shape=(128, 128, 3)),\n    BatchNormalization(),\n    MaxPooling2D(2,2),\n    Dropout(0.25),\n\n    Conv2D(64, (3,3), activation='relu'),\n    BatchNormalization(),\n    MaxPooling2D(2,2),\n    Dropout(0.25),\n\n    Conv2D(128, (3,3), activation='relu'),\n    BatchNormalization(),\n    MaxPooling2D(2,2),\n    Dropout(0.25),\n\n    Flatten(),\n    Dense(128, activation='relu'),\n    Dropout(0.5),\n    Dense(1, activation='sigmoid')\n])\n\n# Compilation of the model\nmodel.compile(\n    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005),\n    loss='binary_crossentropy',\n    metrics=['accuracy']\n)\n\n# Callbacks for early stopping and learning rate adjustment\ncallbacks = [\n    EarlyStopping(patience=5, restore_best_weights=True),\n    ReduceLROnPlateau(patience=3, factor=0.5)\n]\n\n# Training the model\nhistory = model.fit(\n    X_train, y_train,\n    epochs=30,\n    batch_size=32,\n    validation_split=0.2,  # Using 20% of data for validation\n    callbacks=callbacks\n)\n\n# Model Evaluation\ny_pred_prob = model.predict(X_test)\ny_pred = (y_pred_prob > 0.5).astype(int)\n\n# Evaluate performance\nprint(f\"F1 Score: {f1_score(y_test, y_pred)}\")\nprint(f\"Classification Report:\\n{classification_report(y_test, y_pred)}\")\nprint(f\"Confusion Matrix:\\n{confusion_matrix(y_test, y_pred)}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T01:21:07.262484Z","iopub.execute_input":"2025-05-09T01:21:07.262991Z","iopub.status.idle":"2025-05-09T01:21:07.659251Z","shell.execute_reply.started":"2025-05-09T01:21:07.262965Z","shell.execute_reply":"2025-05-09T01:21:07.658130Z"}},"outputs":[{"name":"stdout","text":"Train shape: (126, 360), Test shape: (33, 360)\nEpoch 1/30\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_31/1185908257.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;31m# Training the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m history = model.fit(\n\u001b[0m\u001b[1;32m     60\u001b[0m     \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/models/functional.py\u001b[0m in \u001b[0;36m_adjust_input_rank\u001b[0;34m(self, flat_inputs)\u001b[0m\n\u001b[1;32m    242\u001b[0m                     \u001b[0madjusted\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m                     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    245\u001b[0m                 \u001b[0;34mf\"Invalid input shape for input {x}. Expected shape \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m                 \u001b[0;34mf\"{ref_shape}, but input has incompatible shape {x.shape}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Exception encountered when calling Sequential.call().\n\n\u001b[1mInvalid input shape for input Tensor(\"data:0\", shape=(None, 360), dtype=float32). Expected shape (None, 128, 128, 3), but input has incompatible shape (None, 360)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(None, 360), dtype=float32)\n  • training=True\n  • mask=None"],"ename":"ValueError","evalue":"Exception encountered when calling Sequential.call().\n\n\u001b[1mInvalid input shape for input Tensor(\"data:0\", shape=(None, 360), dtype=float32). Expected shape (None, 128, 128, 3), but input has incompatible shape (None, 360)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(None, 360), dtype=float32)\n  • training=True\n  • mask=None","output_type":"error"}],"execution_count":3}]}